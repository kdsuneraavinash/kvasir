{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KVASIR Dataset (Simple Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data and labels. Here data[i] will contain resized and preprocessed images and label[i] will contain corresponding label for data[i]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image paths from `images` diresctory. Later shuffle image paths with a predetermined seed to maintain reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "RANDOM_SEED = 170081\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(base_path):\n",
    "    \"\"\"Return a list of image files inside the `base_path` \"\"\"\n",
    "\n",
    "    image_paths = []\n",
    "    for (dir_path, _, file_names) in os.walk(base_path):\n",
    "        for file_name in file_names:\n",
    "            if os.extsep not in file_name:\n",
    "                continue\n",
    "            extension = file_name.split(os.extsep)[-1]\n",
    "            if extension not in {'jpg'}:\n",
    "                continue\n",
    "            if '.ipynb' in dir_path:\n",
    "                continue\n",
    "            image_paths.append(os.path.join(dir_path, file_name))\n",
    "\n",
    "    random.shuffle(image_paths)\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = \"../images\"\n",
    "\n",
    "image_paths = get_image_paths(DATASET_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../images/normal-pylorus/c0ffa4e9-ae10-4697-987c-82fcd0e25a9a.jpg',\n",
       " '../images/ulcerative-colitis/022d5583-4d26-430b-96b7-cea372edbd3b.jpg',\n",
       " '../images/normal-pylorus/40f9b93e-e6bc-4ac8-9da9-ba378ee7f7a1.jpg',\n",
       " '../images/normal-cecum/a6043c32-63ff-4819-8e68-8f9c9c29e845.jpg',\n",
       " '../images/normal-pylorus/b725d9ef-aec5-4088-9060-fa6788e3a508.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess each image and store flattened image(32*32*3=3072) in `data` list and label in `labels` list.\n",
    "\n",
    "Note: Each image should be in a directory corresponding to the class is belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Started pre-processing\n",
      "[INFO] 7999/8000 done\n",
      "[INFO] pre-processing completed\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 32\n",
    "\n",
    "print(\"[INFO] Started pre-processing\")\n",
    "\n",
    "for i in range(len(image_paths)):\n",
    "    image_path = image_paths[i]\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = image.flatten()\n",
    "    \n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "    image = np.array(image, dtype='float')\n",
    "    data.append(image / 255.0)\n",
    "    labels.append(label)\n",
    "    \n",
    "    print(f\"[INFO] {i}/{len(image_paths)} done\", end='\\r')\n",
    "\n",
    "# Scale pixel values to be in between 0-1 instead of 0-255. Also converts them to a numpy array.\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "data = data / 255\n",
    "\n",
    "print()\n",
    "print(\"[INFO] pre-processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [7.68935025e-05, 7.68935025e-05, 7.68935025e-05, ...,\n",
       "        4.61361015e-05, 4.61361015e-05, 4.61361015e-05],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [2.92195309e-04, 2.92195309e-04, 2.92195309e-04, ...,\n",
       "        2.92195309e-04, 2.92195309e-04, 2.92195309e-04],\n",
       "       [3.07574010e-05, 3.07574010e-05, 3.07574010e-05, ...,\n",
       "        1.53787005e-05, 1.53787005e-05, 1.53787005e-05],\n",
       "       [3.07574010e-05, 6.15148020e-05, 6.15148020e-05, ...,\n",
       "        3.07574010e-05, 3.07574010e-05, 3.07574010e-05]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal-pylorus', 'ulcerative-colitis', 'normal-pylorus', ...,\n",
       "       'normal-pylorus', 'dyed-lifted-polyps', 'ulcerative-colitis'],\n",
       "      dtype='<U22')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data, labels, \\\n",
    "                                                    test_size=0.25, \\\n",
    "                                                    random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras will assume that,\n",
    "* Labels are encoded as integers\n",
    "* Labels are on-hot encoded\n",
    "\n",
    "So labels have to be encoded as such. For this scikit learn label binarizer is used. However if this is 2-class only, use Keras' to_categorical function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer.fit(labels)\n",
    "\n",
    "train_y = label_binarizer.transform(train_y)\n",
    "test_y = label_binarizer.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and Compiling Keras Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Architecture](https://www.pyimagesearch.com/wp-content/uploads/2018/09/keras_tutorial_simplenn_arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0816 06:41:47.793372 140648136226624 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0816 06:41:47.972087 140648136226624 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0816 06:41:48.013408 140648136226624 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = (IMAGE_SIZE*IMAGE_SIZE*3,)\n",
    "output_size = len(label_binarizer.classes_)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=input_shape, activation='sigmoid'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(output_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model using SGD(Stochastic Gradient Descent) as optimizer and categorical cross-entropy loss (use binary_crossentropy for 2-class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 06:41:48.221048 140648136226624 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0816 06:41:48.235757 140648136226624 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "INITIAL_LEARNING_RATE = 0.01\n",
    "EPOCHS = 50\n",
    "\n",
    "optimizer = SGD(lr=INITIAL_LEARNING_RATE)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer,\\\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0816 06:41:48.543533 140648136226624 deprecation.py:323] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0816 06:41:48.581713 140648136226624 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "6000/6000 [==============================] - 12s 2ms/step - loss: 2.0939 - acc: 0.1283 - val_loss: 2.0954 - val_acc: 0.1395\n",
      "Epoch 2/50\n",
      "6000/6000 [==============================] - 12s 2ms/step - loss: 2.0930 - acc: 0.1278 - val_loss: 2.0810 - val_acc: 0.1310\n",
      "Epoch 3/50\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 2.0926 - acc: 0.1240 - val_loss: 2.0969 - val_acc: 0.1175\n",
      "Epoch 4/50\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 2.0911 - acc: 0.1287 - val_loss: 2.1238 - val_acc: 0.1270\n",
      "Epoch 5/50\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 2.0956 - acc: 0.1187 - val_loss: 2.1030 - val_acc: 0.1220\n",
      "Epoch 6/50\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 2.0931 - acc: 0.1267 - val_loss: 2.1054 - val_acc: 0.1220\n",
      "Epoch 7/50\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 2.0933 - acc: 0.1245 - val_loss: 2.1046 - val_acc: 0.1200\n",
      "Epoch 8/50\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 2.0927 - acc: 0.1262 - val_loss: 2.0924 - val_acc: 0.1395\n",
      "Epoch 9/50\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 2.0893 - acc: 0.1260 - val_loss: 2.0877 - val_acc: 0.1175\n",
      "Epoch 10/50\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 2.0932 - acc: 0.1177 - val_loss: 2.0828 - val_acc: 0.1310\n",
      "Epoch 11/50\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 2.0912 - acc: 0.1152 - val_loss: 2.0938 - val_acc: 0.1270\n",
      "Epoch 12/50\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 2.0920 - acc: 0.1255 - val_loss: 2.0975 - val_acc: 0.1310\n",
      "Epoch 13/50\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 2.0917 - acc: 0.1228 - val_loss: 2.0896 - val_acc: 0.1200\n",
      "Epoch 14/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0911 - acc: 0.1242 - val_loss: 2.0933 - val_acc: 0.1270\n",
      "Epoch 15/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0919 - acc: 0.1225 - val_loss: 2.0966 - val_acc: 0.1125\n",
      "Epoch 16/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0907 - acc: 0.1293 - val_loss: 2.1178 - val_acc: 0.1220\n",
      "Epoch 17/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0918 - acc: 0.1220 - val_loss: 2.1096 - val_acc: 0.1220\n",
      "Epoch 18/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0938 - acc: 0.1213 - val_loss: 2.0987 - val_acc: 0.1270\n",
      "Epoch 19/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0897 - acc: 0.1267 - val_loss: 2.0929 - val_acc: 0.1200\n",
      "Epoch 20/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0918 - acc: 0.1140 - val_loss: 2.1040 - val_acc: 0.1310\n",
      "Epoch 21/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0910 - acc: 0.1247 - val_loss: 2.0929 - val_acc: 0.1125\n",
      "Epoch 22/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0921 - acc: 0.1230 - val_loss: 2.0902 - val_acc: 0.1125\n",
      "Epoch 23/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0921 - acc: 0.1167 - val_loss: 2.1198 - val_acc: 0.1125\n",
      "Epoch 24/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0909 - acc: 0.1283 - val_loss: 2.0937 - val_acc: 0.1125\n",
      "Epoch 25/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0920 - acc: 0.1287 - val_loss: 2.0889 - val_acc: 0.1200\n",
      "Epoch 26/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0917 - acc: 0.1190 - val_loss: 2.0946 - val_acc: 0.1125\n",
      "Epoch 27/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0914 - acc: 0.1238 - val_loss: 2.0886 - val_acc: 0.1200\n",
      "Epoch 28/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0911 - acc: 0.1278 - val_loss: 2.0919 - val_acc: 0.1125\n",
      "Epoch 29/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0919 - acc: 0.1170 - val_loss: 2.0919 - val_acc: 0.1125\n",
      "Epoch 30/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0901 - acc: 0.1317 - val_loss: 2.0897 - val_acc: 0.1305\n",
      "Epoch 31/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0894 - acc: 0.1307 - val_loss: 2.1002 - val_acc: 0.1270\n",
      "Epoch 32/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0900 - acc: 0.1228 - val_loss: 2.0904 - val_acc: 0.1125\n",
      "Epoch 33/50\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.0927 - acc: 0.1132 - val_loss: 2.0911 - val_acc: 0.1310\n",
      "Epoch 34/50\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 2.0906 - acc: 0.1267 - val_loss: 2.0870 - val_acc: 0.1175\n",
      "Epoch 35/50\n",
      "6000/6000 [==============================] - 12s 2ms/step - loss: 2.0907 - acc: 0.1137 - val_loss: 2.0857 - val_acc: 0.1175\n",
      "Epoch 36/50\n",
      "6000/6000 [==============================] - 10s 2ms/step - loss: 2.0909 - acc: 0.1207 - val_loss: 2.0946 - val_acc: 0.1310\n",
      "Epoch 37/50\n",
      "5024/6000 [========================>.....] - ETA: 1s - loss: 2.0917 - acc: 0.1192"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7d3047e61ff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                    validation_data=(test_x, test_y))\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] training completed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network\")\n",
    "\n",
    "history = model.fit(x=train_x, \\\n",
    "                    y=train_y, \\\n",
    "                   batch_size=32,\\\n",
    "                   epochs=EPOCHS,\\\n",
    "                   validation_data=(test_x, test_y))\n",
    "\n",
    "print(\"[INFO] training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x, batch_size=32)\n",
    "\n",
    "correct_predictions = test_y.argmax(axis=1)\n",
    "real_predictions = predictions.argmax(axis=1)\n",
    "\n",
    "class_names = label_binarizer.classes_\n",
    "report = classification_report(correct_predictions, \\\n",
    "                               real_predictions, \\\n",
    "                               target_names=class_names)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_SAVE_PATH = \"simple-nn/evaluation\"\n",
    "\n",
    "epoch_range = np.arange(0, EPOCHS)\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epoch_range, history.history['loss'], label='Loss(Train)')\n",
    "plt.plot(epoch_range, history.history['val_loss'], label='Loss(Test)')\n",
    "plt.plot(epoch_range, history.history['acc'], label='Accuracy(Train)')\n",
    "plt.plot(epoch_range, history.history['val_acc'], label='Accuracy(Test)')\n",
    "\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(PLOT_SAVE_PATH)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model in disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = \"simple-nn/model.hdf5\"\n",
    "CLASSES_SAVE_PATH = \"simple-nn/classes.txt\"\n",
    "\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "\n",
    "with open(CLASSES_SAVE_PATH, 'w') as f:\n",
    "    f.write(\"\\n\".join(label_binarizer.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting for new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_LOAD_PATH = \"../images/dyed-resection-margins/016cc0c1-2a9e-464c-884f-0997561f7dde.jpg\"\n",
    "\n",
    "image = cv2.imread(IMAGE_LOAD_PATH)\n",
    "image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "image = image.flatten()\n",
    "image = image.reshape(1, image.shape[0])\n",
    "\n",
    "model = load_model(MODEL_SAVE_PATH)\n",
    "\n",
    "classes = []\n",
    "with open(CLASSES_SAVE_PATH, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        classes.append(line.strip())\n",
    "\n",
    "prediction = model.predict(image)\n",
    "\n",
    "pred_i = prediction.argmax(axis=1)[0]\n",
    "predicted_label = label_binarizer.classes_[pred_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(label_binarizer.classes_, prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cv2.imread(IMAGE_LOAD_PATH)\n",
    "\n",
    "text = \"{}: {:.2f}%\".format(predicted_label, prediction[0][pred_i] * 100)\n",
    "\n",
    "cv2.putText(output, text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2,\n",
    "\t(255, 255, 0), 3)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
