{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KVASIR Dataset (Simple Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [Keras Tutorial: How to get started with Keras, Deep Learning, and Python](https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Link: [KVASIR Dataset](https://datasets.simula.no/kvasir/data/kvasir-dataset-v2.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = \"../images\"\n",
    "OUTPUT_DIR = \"simple-nn\"\n",
    "CACHE_FILE_NAME = \"./cache/cache_32x32_flat.cache\"\n",
    "IMAGE_EXTENSIONS = {\"jpg\"}\n",
    "\n",
    "FLATTEN = True\n",
    "WIDTH = HEIGHT = 32\n",
    "\n",
    "TEST_PERCENTAGE = 0.2\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets all paths of images in the `DATASET_DIRECTORY`. Here only `jpg` images are loaded. Then image paths are shuffled to randomize input.\n",
    "\n",
    "**IPYNB cache files are ignored since they can be included because of ipython notebook cache files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths():\n",
    "    image_paths = []\n",
    "    for (dir_path, _, file_names) in os.walk(DATASET_DIRECTORY):\n",
    "        for file_name in file_names:\n",
    "            if os.extsep not in file_name:\n",
    "                print(\"Files without extension found: {}\".format(file_name))\n",
    "                continue\n",
    "            extension = file_name.split(os.extsep)[-1]\n",
    "            if extension not in IMAGE_EXTENSIONS:\n",
    "                print(\"Non-image files found: {}\".format(file_name))\n",
    "                continue\n",
    "            if '.ipynb' in dir_path:\n",
    "                print(\"IPyNb caches found: {}\".format(file_name))\n",
    "                continue\n",
    "            image_paths.append(os.path.join(dir_path, file_name))\n",
    "\n",
    "    random.shuffle(image_paths)\n",
    "\n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPyNb caches found: 0053d7cd-549c-48cd-b370-b4ad64a8098a-checkpoint.jpg\n",
      "IPyNb caches found: 009171b0-52ed-4410-a1e3-410c6e746402-checkpoint.jpg\n",
      "IPyNb caches found: 0062bbf3-58d7-435d-b0ca-381703c39911-checkpoint.jpg\n",
      "IPyNb caches found: 00e301cd-5438-4ed7-846b-7d8eaa7cf4b8-checkpoint.jpg\n",
      "IPyNb caches found: 0046dd24-a4c0-4923-a07a-15be898182e2-checkpoint.jpg\n",
      "Found 8000 images\n"
     ]
    }
   ],
   "source": [
    "image_paths = get_image_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and process image given by `image_path` and bring the pixel values to 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "    image = np.array(image, dtype='float') / 255\n",
    "    if FLATTEN:\n",
    "        image = image.flatten()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View one random image of each class after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cannot view flattened images]\n"
     ]
    }
   ],
   "source": [
    "def get_unique_files_of_labels(base_path, image_extensions={'jpg'}):\n",
    "    if FLATTEN:\n",
    "        print(\"[Cannot view flattened images]\")\n",
    "        return\n",
    "    \n",
    "    counter = 0\n",
    "    nrows = 2\n",
    "    ncols = 4\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    \n",
    "    for (dir_path, _, file_names) in os.walk(base_path):\n",
    "        u_image_files = []\n",
    "        for file_name in file_names:\n",
    "            if os.extsep not in file_name:\n",
    "                continue\n",
    "            extension = file_name.split(os.extsep)[-1]\n",
    "            if extension not in image_extensions:\n",
    "                continue\n",
    "            if '.ipynb' in dir_path:\n",
    "                continue\n",
    "            u_image_files.append(os.path.join(dir_path, file_name))\n",
    "        \n",
    "        if len(u_image_files) == 0:\n",
    "            continue\n",
    "        u_image_file = random.choice(u_image_files)\n",
    "\n",
    "        col, row = counter%ncols, counter//ncols\n",
    "        counter += 1\n",
    "        \n",
    "        ax[row, col].imshow(process_image(u_image_file))\n",
    "        ax[row, col].axis('off')\n",
    "    print(\"Random processed images of each class\")\n",
    "    plt.show()\n",
    "    \n",
    "get_unique_files_of_labels(DATASET_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset from `DATASET_DIRECTORY` into memory and return a tuple of (images, labels) where `image[i]` is the i'th preprocessed image normalized into 0-1 range and `labels[i]` is the label of i'th image.\n",
    "\n",
    "`DATASET_DIRECTORY` must have directories representing labels and images inside each directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"Searching for cache file: \" + CACHE_FILE_NAME)\n",
    "\n",
    "    if os.path.exists(CACHE_FILE_NAME):\n",
    "        print(\"Cache file found. Loading from cache.\")\n",
    "        with open(CACHE_FILE_NAME, 'rb') as fr:\n",
    "            images, labels = pickle.load(fr)\n",
    "    else:\n",
    "        print(\"Cache file not found\")\n",
    "        print(\"Started loading dataset\")\n",
    "\n",
    "        for ind, image_path in enumerate(image_paths):\n",
    "            image = process_image(image_path)\n",
    "            label = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "            print(f\"Loaded {ind}/{len(image_paths)} images.\", end=\"\\r\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        images = np.array(images, dtype='float')\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        with open(CACHE_FILE_NAME, 'wb') as fw:\n",
    "            pickle.dump((images, labels), fw)\n",
    "\n",
    "    print(\"Dataset loaded into memory\")\n",
    "    return images, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for cache file: ./cache/cache_32x32_flat.cache\n",
      "Cache file found. Loading from cache.\n",
      "Dataset loaded into memory\n"
     ]
    }
   ],
   "source": [
    "images, labels = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FLATTEN:\n",
    "    plt.title(labels[0])\n",
    "    plt.imshow(images[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras will assume that,\n",
    "* Labels are encoded as integers\n",
    "* Labels are on-hot encoded\n",
    "\n",
    "So labels have to be encoded as such. For this scikit learn label binarizer is used. However if this is 2-class only, use Keras' `to_categorical` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "encoded_labels = label_binarizer.fit_transform(labels)\n",
    "class_names = label_binarizer.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(images, encoded_labels,\n",
    "                                                    test_size=TEST_PERCENTAGE,\n",
    "                                                    stratify=encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FLATTEN:\n",
    "    plt.title(str(train_y[0]))\n",
    "    plt.imshow(train_x[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FLATTEN:\n",
    "    plt.title(str(test_y[0]))\n",
    "    plt.imshow(test_x[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and Compiling Keras Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Architecture](https://www.pyimagesearch.com/wp-content/uploads/2018/09/keras_tutorial_simplenn_arch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile a simple feed forward neural network.\n",
    "\n",
    "`(Dense => Sigmoid) => (Dense => Sigmoid) => (Dense => Sigmoid) => (Dense => Sigmoid)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 15:40:05.259157 139916910597952 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0827 15:40:05.279465 139916910597952 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0827 15:40:05.286620 139916910597952 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0827 15:40:05.373691 139916910597952 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0827 15:40:05.388965 139916910597952 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = (WIDTH*HEIGHT*3, )\n",
    "output_nodes = len(class_names)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=input_shape, activation='sigmoid'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(output_nodes, activation='sigmoid'))\n",
    "\n",
    "optimizer = SGD(lr=LEARNING_RATE)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0827 15:40:05.554812 139916910597952 deprecation.py:323] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0827 15:40:05.623959 139916910597952 deprecation_wrapper.py:119] From /home/kdsuneraavinash/Programs/miniconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 2.0684 - acc: 0.1694 - val_loss: 2.0380 - val_acc: 0.1856\n",
      "Epoch 2/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 2.0033 - acc: 0.2739 - val_loss: 1.9663 - val_acc: 0.1944\n",
      "Epoch 3/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 1.8974 - acc: 0.3447 - val_loss: 1.8265 - val_acc: 0.3319\n",
      "Epoch 4/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 1.7490 - acc: 0.3919 - val_loss: 1.6555 - val_acc: 0.4956\n",
      "Epoch 5/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 1.5894 - acc: 0.4486 - val_loss: 1.5134 - val_acc: 0.3663\n",
      "Epoch 6/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 1.4525 - acc: 0.4731 - val_loss: 1.3910 - val_acc: 0.4869\n",
      "Epoch 7/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 1.3376 - acc: 0.5012 - val_loss: 1.2852 - val_acc: 0.4650\n",
      "Epoch 8/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 1.2484 - acc: 0.5241 - val_loss: 1.1877 - val_acc: 0.5687\n",
      "Epoch 9/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 1.1749 - acc: 0.5473 - val_loss: 1.1248 - val_acc: 0.5413\n",
      "Epoch 10/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 1.1178 - acc: 0.5566 - val_loss: 1.0746 - val_acc: 0.5844\n",
      "Epoch 11/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 1.0706 - acc: 0.5659 - val_loss: 1.0317 - val_acc: 0.5794\n",
      "Epoch 12/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 1.0287 - acc: 0.5834 - val_loss: 0.9927 - val_acc: 0.5775\n",
      "Epoch 13/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 0.9971 - acc: 0.5942 - val_loss: 0.9604 - val_acc: 0.6056\n",
      "Epoch 14/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 0.9679 - acc: 0.6009 - val_loss: 0.9374 - val_acc: 0.6231\n",
      "Epoch 15/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 0.9429 - acc: 0.6120 - val_loss: 0.9041 - val_acc: 0.6294\n",
      "Epoch 16/50\n",
      "6400/6400 [==============================] - 6s 1ms/step - loss: 0.9188 - acc: 0.6194 - val_loss: 0.8862 - val_acc: 0.6331\n",
      "Epoch 17/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.9014 - acc: 0.6198 - val_loss: 0.8700 - val_acc: 0.6456\n",
      "Epoch 18/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.8821 - acc: 0.6300 - val_loss: 0.8534 - val_acc: 0.6606\n",
      "Epoch 19/50\n",
      "6400/6400 [==============================] - 6s 993us/step - loss: 0.8652 - acc: 0.6441 - val_loss: 0.8319 - val_acc: 0.6544\n",
      "Epoch 20/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.8497 - acc: 0.6434 - val_loss: 0.8286 - val_acc: 0.6475\n",
      "Epoch 21/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.8384 - acc: 0.6472 - val_loss: 0.8068 - val_acc: 0.6756\n",
      "Epoch 22/50\n",
      "6400/6400 [==============================] - 6s 1ms/step - loss: 0.8251 - acc: 0.6467 - val_loss: 0.7958 - val_acc: 0.6594\n",
      "Epoch 23/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.8121 - acc: 0.6548 - val_loss: 0.7869 - val_acc: 0.6781\n",
      "Epoch 24/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.8036 - acc: 0.6613 - val_loss: 0.7893 - val_acc: 0.6469\n",
      "Epoch 25/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7943 - acc: 0.6584 - val_loss: 0.7692 - val_acc: 0.6887\n",
      "Epoch 26/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7842 - acc: 0.6631 - val_loss: 0.7683 - val_acc: 0.6819\n",
      "Epoch 27/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7783 - acc: 0.6720 - val_loss: 0.7638 - val_acc: 0.6663\n",
      "Epoch 28/50\n",
      "6400/6400 [==============================] - 6s 989us/step - loss: 0.7712 - acc: 0.6670 - val_loss: 0.7510 - val_acc: 0.6787\n",
      "Epoch 29/50\n",
      "6400/6400 [==============================] - 6s 1ms/step - loss: 0.7646 - acc: 0.6714 - val_loss: 0.7424 - val_acc: 0.6894\n",
      "Epoch 30/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7588 - acc: 0.6648 - val_loss: 0.7380 - val_acc: 0.6881\n",
      "Epoch 31/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7526 - acc: 0.6708 - val_loss: 0.7389 - val_acc: 0.6825\n",
      "Epoch 32/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7482 - acc: 0.6748 - val_loss: 0.7275 - val_acc: 0.6950\n",
      "Epoch 33/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7424 - acc: 0.6791 - val_loss: 0.7299 - val_acc: 0.6937\n",
      "Epoch 34/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7360 - acc: 0.6777 - val_loss: 0.7222 - val_acc: 0.6906\n",
      "Epoch 35/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7339 - acc: 0.6783 - val_loss: 0.7192 - val_acc: 0.6869\n",
      "Epoch 36/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7290 - acc: 0.6795 - val_loss: 0.7311 - val_acc: 0.6819\n",
      "Epoch 37/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7262 - acc: 0.6775 - val_loss: 0.7127 - val_acc: 0.6931\n",
      "Epoch 38/50\n",
      "6400/6400 [==============================] - 7s 1ms/step - loss: 0.7226 - acc: 0.6863 - val_loss: 0.7155 - val_acc: 0.6844\n",
      "Epoch 39/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 0.7182 - acc: 0.6763 - val_loss: 0.7101 - val_acc: 0.6981\n",
      "Epoch 40/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 0.7160 - acc: 0.6830 - val_loss: 0.7118 - val_acc: 0.6831\n",
      "Epoch 41/50\n",
      "6400/6400 [==============================] - 9s 1ms/step - loss: 0.7139 - acc: 0.6850 - val_loss: 0.7026 - val_acc: 0.7013\n",
      "Epoch 42/50\n",
      "6400/6400 [==============================] - 10s 1ms/step - loss: 0.7082 - acc: 0.6869 - val_loss: 0.7017 - val_acc: 0.6906\n",
      "Epoch 43/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 0.7069 - acc: 0.6856 - val_loss: 0.7002 - val_acc: 0.7037\n",
      "Epoch 44/50\n",
      "6400/6400 [==============================] - 8s 1ms/step - loss: 0.7047 - acc: 0.6806 - val_loss: 0.7002 - val_acc: 0.6963\n",
      "Epoch 45/50\n",
      "5216/6400 [=======================>......] - ETA: 1s - loss: 0.6962 - acc: 0.6854"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_x,\n",
    "                    y=train_y,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=N_EPOCHS,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate report on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_report():\n",
    "    predictions = model.predict(test_x, batch_size=BATCH_SIZE)\n",
    "\n",
    "    y_true = test_y.argmax(axis=1)\n",
    "    y_pred = predictions.argmax(axis=1)\n",
    "\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "    report_output_path = os.path.join(OUTPUT_DIR, 'evaluation.txt')\n",
    "\n",
    "    with open(report_output_path, 'w') as fw:\n",
    "        fw.write(str(report))\n",
    "\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate, show and save a plot on accurcy and loss by epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart():\n",
    "    x_axis_values = np.arange(0, N_EPOCHS)\n",
    "    plt.style.use('seaborn-white')\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(x_axis_values, history.history['loss'], label='Loss(Train)')\n",
    "    plt.plot(x_axis_values,\n",
    "             history.history['val_loss'], label='Loss(Test)')\n",
    "    plt.plot(x_axis_values,\n",
    "             history.history['acc'], label='Accuracy(Train)')\n",
    "    plt.plot(x_axis_values,\n",
    "             history.history['val_acc'], label='Accuracy(Test)')\n",
    "\n",
    "    plt.title(\"Training Loss and Accuracy (Small VGGNet)\")\n",
    "    plt.xlabel(\"Epoch Number\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    chart_output_path = os.path.join(OUTPUT_DIR, 'chart')\n",
    "    plt.savefig(chart_output_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_output_path = os.path.join(OUTPUT_DIR, 'classes.txt')\n",
    "model_output_path = os.path.join(OUTPUT_DIR, 'model.hdf5')\n",
    "\n",
    "model.save(model_output_path)\n",
    "with open(classes_output_path, 'w') as fw:\n",
    "    fw.write('\\n'.join(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = HEIGHT = 32\n",
    "OUTPUT_DIR = \"simple-nn\"\n",
    "\n",
    "IMAGE_LOAD_PATH = \"../images/dyed-resection-margins/016cc0c1-2a9e-464c-884f-0997561f7dde.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(IMAGE_LOAD_PATH)\n",
    "\n",
    "model_output_path = os.path.join(OUTPUT_DIR, 'model.hdf5')\n",
    "classes_output_path = os.path.join(OUTPUT_DIR, 'classes.txt')\n",
    "\n",
    "image = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "image = image.flatten()\n",
    "image = image.reshape(1, image.shape[0])\n",
    "\n",
    "model = load_model(model_output_path)\n",
    "\n",
    "class_names = []\n",
    "with open(classes_output_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        class_names.append(line.strip())\n",
    "\n",
    "prediction = model.predict(image)\n",
    "\n",
    "pred_i = prediction.argmax(axis=1)[0]\n",
    "predicted_label = class_names[pred_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw output prediction on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cv2.imread(IMAGE_LOAD_PATH)\n",
    "\n",
    "text = \"{}: {:.2f}%\".format(predicted_label, prediction[0][pred_i] * 100)\n",
    "\n",
    "cv2.putText(output, text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2,\n",
    "\t(255, 255, 0), 3)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(output)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
